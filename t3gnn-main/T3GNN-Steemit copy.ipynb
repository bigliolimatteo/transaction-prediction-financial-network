{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76e04ce",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a05d94c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/hcn931t94jbcxvgv2ndg66q80000gq/T/ipykernel_72877/2566862369.py:16: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, GRUCell\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import roc_auc_score,average_precision_score\n",
    "\n",
    "import random\n",
    "\n",
    "import bisect \n",
    "\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from itertools import permutations\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.transforms import SVDFeatureReduction\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.transforms import RandomLinkSplit,NormalizeFeatures,Constant,OneHotDegree\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import GCNConv,SAGEConv,GATv2Conv, GINConv, Linear\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8b40a",
   "metadata": {},
   "source": [
    "# LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "041d8f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from steemitdata import get_steemit_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "502cf464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snapshots with constant encoder as node features\n",
    "#Snapshots with textual features as node features\n",
    "\n",
    "snapshots_c = get_steemit_dataset(preprocess='constant')\n",
    "snapshots_t = get_steemit_dataset(preprocess='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db20fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snapshots with random features as node features\n",
    "snapshots_ts = get_steemit_dataset(preprocess='constant')\n",
    "for snap in snapshots_ts:\n",
    "    snap.x = torch.randn(snap.num_nodes, 384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff34ed04",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9262266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from t3gnn import T3GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ca9a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roland_test(model, test_data, data, isnap, device='cpu'):\n",
    "    model.eval()\n",
    "\n",
    "    test_data = test_data.to(device)\n",
    "\n",
    "    h, _ = model(test_data.x, test_data.edge_index, edge_label_index = test_data.edge_label_index, isnap=isnap)\n",
    "    \n",
    "    pred_cont_link = torch.sigmoid(h).cpu().detach().numpy()\n",
    "    \n",
    "    label_link = test_data.edge_label.cpu().detach().numpy()\n",
    "      \n",
    "    avgpr_score_link = average_precision_score(label_link, pred_cont_link)\n",
    "    \n",
    "    return avgpr_score_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78c87220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "def roland_train_single_snapshot(model, data, train_data, val_data, test_data, isnap,\\\n",
    "                          last_embeddings, optimizer, device='cpu', num_epochs=50, verbose=False):\n",
    "    \n",
    "    avgpr_val_max = 0\n",
    "    best_model = model\n",
    "    train_data = train_data.to(device)\n",
    "    best_epoch = -1\n",
    "    best_current_embeddings = []\n",
    "    \n",
    "    avgpr_trains = []\n",
    "    #avgpr_vals = []\n",
    "    avgpr_tests = []\n",
    "    \n",
    "    tol = 1\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        ## Note\n",
    "        ## 1. Zero grad the optimizer\n",
    "        ## 2. Compute loss and backpropagate\n",
    "        ## 3. Update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred,\\\n",
    "        current_embeddings =\\\n",
    "            model(train_data.x, train_data.edge_index, edge_label_index = train_data.edge_label_index,\\\n",
    "                  isnap=isnap, previous_embeddings=last_embeddings)\n",
    "        \n",
    "        loss = model.loss(pred, train_data.edge_label.type_as(pred)) #loss to fine tune on current snapshot\n",
    "\n",
    "        loss.backward(retain_graph=True)  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "        log = 'Epoch: {:03d}\\n AVGPR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n MRR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n F1-Score Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n Loss: {}'\n",
    "        avgpr_score_val  = roland_test(model, val_data, data, isnap, device)\n",
    "        \n",
    "        if avgpr_val_max-tol <= avgpr_score_val:\n",
    "            avgpr_val_max = avgpr_score_val\n",
    "            best_epoch = epoch\n",
    "            best_current_embeddings = current_embeddings\n",
    "            best_model = model\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    avgpr_score_test = roland_test(model, test_data, data, isnap, device)\n",
    "            \n",
    "    return best_model, optimizer, avgpr_score_test, best_current_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97829012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_roland(snapshots, hidden_dimension, update='gru', device='cpu'):\n",
    "    \"\"\"\n",
    "        Train and evaluate T3GNN with historical negative edges in the live update setting\n",
    "    \"\"\"\n",
    "    num_snap = len(snapshots)\n",
    "    input_channels = snapshots[0].x.size(1)\n",
    "    num_nodes = snapshots[0].x.size(0)\n",
    "    last_embeddings = [torch.Tensor([[0 for i in range(hidden_dimension)] for j in range(num_nodes)])]\n",
    " \n",
    "    avgpr_test_singles = []\n",
    "    \n",
    "    roland = T3GNN(input_channels, 2, hidden_dimension, dropout=0.3, update=update)\n",
    "    rolopt = torch.optim.Adam(params=roland.parameters(), lr=0.01, weight_decay = 5e-3)\n",
    "    roland.reset_parameters()\n",
    "    \n",
    "    for i in range(num_snap-1):\n",
    "        #CREATE TRAIN + VAL + TEST SET FOR THE CURRENT SNAP\n",
    "        snapshot = copy.deepcopy(snapshots[i])\n",
    "        num_current_edges = len(snapshot.edge_index[0])\n",
    "        transform = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "        train_data, _, val_data = transform(snapshot)\n",
    "        test_data = copy.deepcopy(snapshots[i+1])\n",
    "        \n",
    "        #NEGATIVE SET: EDGES CLOSED IN THE PAST BUT NON IN THE CURRENT TEST SET\n",
    "        past_edges = set(zip([int(e) for e in snapshot.edge_index[0]],\\\n",
    "                             [int(e) for e in snapshot.edge_index[1]]))\n",
    "        current_edges = set(zip([int(e) for e in test_data.edge_index[0]],\\\n",
    "                             [int(e) for e in test_data.edge_index[1]]))\n",
    "        \n",
    "        negative_edges = list(past_edges.difference(current_edges))[:test_data.edge_index.size(1)]\n",
    "        future_neg_edge_index = torch.Tensor([[a[0] for a in negative_edges],\\\n",
    "                                                 [a[1] for a in negative_edges]]).long()\n",
    "        \n",
    "        num_pos_edge = test_data.edge_index.size(1)\n",
    "        num_neg_edge = future_neg_edge_index.size(1)\n",
    "        test_data.edge_label = torch.Tensor(np.array([1 for i in range(num_pos_edge)] + [0 for i in range(num_neg_edge)]))\n",
    "        test_data.edge_label_index = torch.cat([test_data.edge_index, future_neg_edge_index], dim=-1)\n",
    "        \n",
    "\n",
    "        print(train_data)\n",
    "        print(val_data)\n",
    "        print(test_data)\n",
    "        print(last_embeddings[0].shape)\n",
    "        print(last_embeddings[1].shape)\n",
    "        #TRAIN AND TEST THE MODEL FOR THE CURRENT SNAP\n",
    "        roland, rolopt, avgpr_test, last_embeddings =\\\n",
    "            roland_train_single_snapshot(roland, snapshot, train_data, val_data, test_data, i,\\\n",
    "                                  last_embeddings, rolopt)\n",
    "        \n",
    "        \n",
    "        #SAVE AND DISPLAY EVALUATION\n",
    "        print(f'Snapshot: {i}\\n\\tT3GNN AVGPR Test: {avgpr_test}')\n",
    "        avgpr_test_singles.append(avgpr_test)\n",
    "        \n",
    "    avgpr_test_all = sum(avgpr_test_singles)/len(avgpr_test_singles)\n",
    "    \n",
    "    print(f'T3GNN AVGPR over time Test: {avgpr_test_all}')\n",
    "    \n",
    "    return avgpr_test_singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b53f5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(num_nodes=14814, edge_index=[2, 29953], x=[14814, 1], edge_label=[59906], edge_label_index=[2, 59906])\n",
      "Data(num_nodes=14814, edge_index=[2, 29953], x=[14814, 1], edge_label=[19968], edge_label_index=[2, 19968])\n",
      "Data(num_nodes=14814, edge_index=[2, 3144], x=[14814, 1], edge_label=[6288], edge_label_index=[2, 6288])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 32])\n",
      "Snapshot: 0\n",
      "\tT3GNN AVGPR Test: 0.7351054408954614\n",
      "Data(num_nodes=14814, edge_index=[2, 2358], x=[14814, 1], edge_label=[4716], edge_label_index=[2, 4716])\n",
      "Data(num_nodes=14814, edge_index=[2, 2358], x=[14814, 1], edge_label=[1572], edge_label_index=[2, 1572])\n",
      "Data(num_nodes=14814, edge_index=[2, 2751], x=[14814, 1], edge_label=[5502], edge_label_index=[2, 5502])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 1\n",
      "\tT3GNN AVGPR Test: 0.58226996790924\n",
      "Data(num_nodes=14814, edge_index=[2, 2064], x=[14814, 1], edge_label=[4128], edge_label_index=[2, 4128])\n",
      "Data(num_nodes=14814, edge_index=[2, 2064], x=[14814, 1], edge_label=[1374], edge_label_index=[2, 1374])\n",
      "Data(num_nodes=14814, edge_index=[2, 2906], x=[14814, 1], edge_label=[5428], edge_label_index=[2, 5428])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 2\n",
      "\tT3GNN AVGPR Test: 0.5977619426938363\n",
      "Data(num_nodes=14814, edge_index=[2, 2180], x=[14814, 1], edge_label=[4360], edge_label_index=[2, 4360])\n",
      "Data(num_nodes=14814, edge_index=[2, 2180], x=[14814, 1], edge_label=[1452], edge_label_index=[2, 1452])\n",
      "Data(num_nodes=14814, edge_index=[2, 2355], x=[14814, 1], edge_label=[4710], edge_label_index=[2, 4710])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 3\n",
      "\tT3GNN AVGPR Test: 0.7587257323265056\n",
      "Data(num_nodes=14814, edge_index=[2, 1767], x=[14814, 1], edge_label=[3534], edge_label_index=[2, 3534])\n",
      "Data(num_nodes=14814, edge_index=[2, 1767], x=[14814, 1], edge_label=[1176], edge_label_index=[2, 1176])\n",
      "Data(num_nodes=14814, edge_index=[2, 2415], x=[14814, 1], edge_label=[4714], edge_label_index=[2, 4714])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 4\n",
      "\tT3GNN AVGPR Test: 0.8285132334673591\n",
      "Data(num_nodes=14814, edge_index=[2, 1812], x=[14814, 1], edge_label=[3624], edge_label_index=[2, 3624])\n",
      "Data(num_nodes=14814, edge_index=[2, 1812], x=[14814, 1], edge_label=[1206], edge_label_index=[2, 1206])\n",
      "Data(num_nodes=14814, edge_index=[2, 3065], x=[14814, 1], edge_label=[5424], edge_label_index=[2, 5424])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 5\n",
      "\tT3GNN AVGPR Test: 0.8775694622373111\n",
      "Data(num_nodes=14814, edge_index=[2, 2299], x=[14814, 1], edge_label=[4598], edge_label_index=[2, 4598])\n",
      "Data(num_nodes=14814, edge_index=[2, 2299], x=[14814, 1], edge_label=[1532], edge_label_index=[2, 1532])\n",
      "Data(num_nodes=14814, edge_index=[2, 2330], x=[14814, 1], edge_label=[4660], edge_label_index=[2, 4660])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 6\n",
      "\tT3GNN AVGPR Test: 0.8188610698981073\n",
      "Data(num_nodes=14814, edge_index=[2, 1748], x=[14814, 1], edge_label=[3496], edge_label_index=[2, 3496])\n",
      "Data(num_nodes=14814, edge_index=[2, 1748], x=[14814, 1], edge_label=[1164], edge_label_index=[2, 1164])\n",
      "Data(num_nodes=14814, edge_index=[2, 2063], x=[14814, 1], edge_label=[4126], edge_label_index=[2, 4126])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 7\n",
      "\tT3GNN AVGPR Test: 0.6475283959149136\n",
      "Data(num_nodes=14814, edge_index=[2, 1548], x=[14814, 1], edge_label=[3096], edge_label_index=[2, 3096])\n",
      "Data(num_nodes=14814, edge_index=[2, 1548], x=[14814, 1], edge_label=[1030], edge_label_index=[2, 1030])\n",
      "Data(num_nodes=14814, edge_index=[2, 2580], x=[14814, 1], edge_label=[4405], edge_label_index=[2, 4405])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 8\n",
      "\tT3GNN AVGPR Test: 0.7156778908568449\n",
      "Data(num_nodes=14814, edge_index=[2, 1935], x=[14814, 1], edge_label=[3870], edge_label_index=[2, 3870])\n",
      "Data(num_nodes=14814, edge_index=[2, 1935], x=[14814, 1], edge_label=[1290], edge_label_index=[2, 1290])\n",
      "Data(num_nodes=14814, edge_index=[2, 3175], x=[14814, 1], edge_label=[5461], edge_label_index=[2, 5461])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 9\n",
      "\tT3GNN AVGPR Test: 0.6490937398990931\n",
      "Data(num_nodes=14814, edge_index=[2, 2382], x=[14814, 1], edge_label=[4764], edge_label_index=[2, 4764])\n",
      "Data(num_nodes=14814, edge_index=[2, 2382], x=[14814, 1], edge_label=[1586], edge_label_index=[2, 1586])\n",
      "Data(num_nodes=14814, edge_index=[2, 4092], x=[14814, 1], edge_label=[7168], edge_label_index=[2, 7168])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 10\n",
      "\tT3GNN AVGPR Test: 0.7356218113605673\n",
      "Data(num_nodes=14814, edge_index=[2, 3069], x=[14814, 1], edge_label=[6138], edge_label_index=[2, 6138])\n",
      "Data(num_nodes=14814, edge_index=[2, 3069], x=[14814, 1], edge_label=[2046], edge_label_index=[2, 2046])\n",
      "Data(num_nodes=14814, edge_index=[2, 3699], x=[14814, 1], edge_label=[7398], edge_label_index=[2, 7398])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 11\n",
      "\tT3GNN AVGPR Test: 0.8199715355835698\n",
      "Data(num_nodes=14814, edge_index=[2, 2775], x=[14814, 1], edge_label=[5550], edge_label_index=[2, 5550])\n",
      "Data(num_nodes=14814, edge_index=[2, 2775], x=[14814, 1], edge_label=[1848], edge_label_index=[2, 1848])\n",
      "Data(num_nodes=14814, edge_index=[2, 3334], x=[14814, 1], edge_label=[6668], edge_label_index=[2, 6668])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 12\n",
      "\tT3GNN AVGPR Test: 0.8956155516355451\n",
      "Data(num_nodes=14814, edge_index=[2, 2501], x=[14814, 1], edge_label=[5002], edge_label_index=[2, 5002])\n",
      "Data(num_nodes=14814, edge_index=[2, 2501], x=[14814, 1], edge_label=[1666], edge_label_index=[2, 1666])\n",
      "Data(num_nodes=14814, edge_index=[2, 2969], x=[14814, 1], edge_label=[4950], edge_label_index=[2, 4950])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 13\n",
      "\tT3GNN AVGPR Test: 0.6376093071471413\n",
      "Data(num_nodes=14814, edge_index=[2, 2227], x=[14814, 1], edge_label=[4454], edge_label_index=[2, 4454])\n",
      "Data(num_nodes=14814, edge_index=[2, 2227], x=[14814, 1], edge_label=[1484], edge_label_index=[2, 1484])\n",
      "Data(num_nodes=14814, edge_index=[2, 2810], x=[14814, 1], edge_label=[4553], edge_label_index=[2, 4553])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 14\n",
      "\tT3GNN AVGPR Test: 0.6814578025571232\n",
      "Data(num_nodes=14814, edge_index=[2, 2108], x=[14814, 1], edge_label=[4216], edge_label_index=[2, 4216])\n",
      "Data(num_nodes=14814, edge_index=[2, 2108], x=[14814, 1], edge_label=[1404], edge_label_index=[2, 1404])\n",
      "Data(num_nodes=14814, edge_index=[2, 3491], x=[14814, 1], edge_label=[4898], edge_label_index=[2, 4898])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 15\n",
      "\tT3GNN AVGPR Test: 0.7116855896546661\n",
      "Data(num_nodes=14814, edge_index=[2, 2619], x=[14814, 1], edge_label=[5238], edge_label_index=[2, 5238])\n",
      "Data(num_nodes=14814, edge_index=[2, 2619], x=[14814, 1], edge_label=[1744], edge_label_index=[2, 1744])\n",
      "Data(num_nodes=14814, edge_index=[2, 2974], x=[14814, 1], edge_label=[4841], edge_label_index=[2, 4841])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 16\n",
      "\tT3GNN AVGPR Test: 0.6932316020015533\n",
      "Data(num_nodes=14814, edge_index=[2, 2231], x=[14814, 1], edge_label=[4462], edge_label_index=[2, 4462])\n",
      "Data(num_nodes=14814, edge_index=[2, 2231], x=[14814, 1], edge_label=[1486], edge_label_index=[2, 1486])\n",
      "Data(num_nodes=14814, edge_index=[2, 2124], x=[14814, 1], edge_label=[3985], edge_label_index=[2, 3985])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 17\n",
      "\tT3GNN AVGPR Test: 0.6649613883124483\n",
      "Data(num_nodes=14814, edge_index=[2, 1593], x=[14814, 1], edge_label=[3186], edge_label_index=[2, 3186])\n",
      "Data(num_nodes=14814, edge_index=[2, 1593], x=[14814, 1], edge_label=[1062], edge_label_index=[2, 1062])\n",
      "Data(num_nodes=14814, edge_index=[2, 1900], x=[14814, 1], edge_label=[3079], edge_label_index=[2, 3079])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 18\n",
      "\tT3GNN AVGPR Test: 0.6625212999577594\n",
      "Data(num_nodes=14814, edge_index=[2, 1425], x=[14814, 1], edge_label=[2850], edge_label_index=[2, 2850])\n",
      "Data(num_nodes=14814, edge_index=[2, 1425], x=[14814, 1], edge_label=[950], edge_label_index=[2, 950])\n",
      "Data(num_nodes=14814, edge_index=[2, 2308], x=[14814, 1], edge_label=[3307], edge_label_index=[2, 3307])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 19\n",
      "\tT3GNN AVGPR Test: 0.710089157934558\n",
      "Data(num_nodes=14814, edge_index=[2, 1731], x=[14814, 1], edge_label=[3462], edge_label_index=[2, 3462])\n",
      "Data(num_nodes=14814, edge_index=[2, 1731], x=[14814, 1], edge_label=[1154], edge_label_index=[2, 1154])\n",
      "Data(num_nodes=14814, edge_index=[2, 2386], x=[14814, 1], edge_label=[3897], edge_label_index=[2, 3897])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 20\n",
      "\tT3GNN AVGPR Test: 0.6405675862917289\n",
      "Data(num_nodes=14814, edge_index=[2, 1790], x=[14814, 1], edge_label=[3580], edge_label_index=[2, 3580])\n",
      "Data(num_nodes=14814, edge_index=[2, 1790], x=[14814, 1], edge_label=[1192], edge_label_index=[2, 1192])\n",
      "Data(num_nodes=14814, edge_index=[2, 1683], x=[14814, 1], edge_label=[3304], edge_label_index=[2, 3304])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 21\n",
      "\tT3GNN AVGPR Test: 0.6548980994952015\n",
      "Data(num_nodes=14814, edge_index=[2, 1263], x=[14814, 1], edge_label=[2526], edge_label_index=[2, 2526])\n",
      "Data(num_nodes=14814, edge_index=[2, 1263], x=[14814, 1], edge_label=[840], edge_label_index=[2, 840])\n",
      "Data(num_nodes=14814, edge_index=[2, 1710], x=[14814, 1], edge_label=[2698], edge_label_index=[2, 2698])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 22\n",
      "\tT3GNN AVGPR Test: 0.667595646081665\n",
      "Data(num_nodes=14814, edge_index=[2, 1283], x=[14814, 1], edge_label=[2566], edge_label_index=[2, 2566])\n",
      "Data(num_nodes=14814, edge_index=[2, 1283], x=[14814, 1], edge_label=[854], edge_label_index=[2, 854])\n",
      "Data(num_nodes=14814, edge_index=[2, 2026], x=[14814, 1], edge_label=[2933], edge_label_index=[2, 2933])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 23\n",
      "\tT3GNN AVGPR Test: 0.773586972167217\n",
      "Data(num_nodes=14814, edge_index=[2, 1520], x=[14814, 1], edge_label=[3040], edge_label_index=[2, 3040])\n",
      "Data(num_nodes=14814, edge_index=[2, 1520], x=[14814, 1], edge_label=[1012], edge_label_index=[2, 1012])\n",
      "Data(num_nodes=14814, edge_index=[2, 2387], x=[14814, 1], edge_label=[3384], edge_label_index=[2, 3384])\n",
      "torch.Size([14814, 64])\n",
      "torch.Size([14814, 64])\n",
      "Snapshot: 24\n",
      "\tT3GNN AVGPR Test: 0.7600941023509666\n",
      "T3GNN AVGPR over time Test: 0.7168245731452152\n"
     ]
    }
   ],
   "source": [
    "hidden_conv1 = 64\n",
    "hidden_conv2 = 32\n",
    "\n",
    "ro_constant_avgpr = train_roland(snapshots_c, hidden_conv1, hidden_conv2, update='mlp') #no-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754d0698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
